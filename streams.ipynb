{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade openai\nimport openai\nimport time\nopenai.api_key = user_secrets.get_secret(\"OPENAI_API_KEY\")\nstartime = time.time()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### STREAM CHATGPT API RESPONSES\ndelay_time = 0.01 #  faster\nmax_response_length = 200\n\n# ASK QUESTION\nprompt = input(\"Ask a question: \")\nstart_time = time.time()\n\nresponse = openai.ChatCompletion.create(\n    # CHATPG GPT API REQQUEST\n    model='gpt-3.5-turbo',\n    messages=[\n        {'role': 'user', 'content': f'{prompt}'}\n    ],\n    max_tokens=max_response_length,\n    temperature=0,\n    stream=True,  # this time, we set stream=True\n)\n\nfor event in response: \n    # STREAM THE ANSWER\n    print(answer, end='', flush=True) # Print the response\n    \n    # RETRIEVE THE TEXT FROM THE RESPONSE\n    event_time = time.time() - start_time  # CALCULATE TIME DELAY BY THE EVENT\n    event_text = event['choices'][0]['delta'] # EVENT DELTA RESPONSE\n    answer = event_text.get('content', '') # RETRIEVE CONTENT\n    time.sleep(delay_time)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"collected_events = []\ncompletion_text = []\nspeed = 0.05 #smaller is faster\nmax_response_length = 200\nstart_time = time.time()\nprompt = input(\"Ask a question: \")\n# Generate Answer\nresponse = openai.Completion.create(\n    model='text-davinci-003',\n    prompt=prompt,\n    max_tokens=max_response_length,\n    temperature=0,\n    stream=True,  # this time, we set stream=True\n)\n\n# Stream Answer\nfor event in response:\n    event_time = time.time() - start_time  # calculate the time delay of the event\n    collected_events.append(event)  # save the event response\n    event_text = event['choices'][0]['text']  # extract the text\n    completion_text += event_text  # append the text\n    time.sleep(speed)\n    print(f\"{event_text}\", end=\"\", flush=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}
